{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f50772",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490bb25",
   "metadata": {},
   "source": [
    "## 提取question_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d63b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 150000 questions!"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3c339cd96bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./generated_file/q_temp_output.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mq_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fd/lib/python3.9/csv.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# Used only for its side effect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question_dic = {}\n",
    "now_index = 0\n",
    "\n",
    "question_infos = []\n",
    "\n",
    "# 先找到所有python问题，他们的问题数量以及他们是否有最佳答案\n",
    "with open(\"./generated_file/q_temp_output.csv\", \"r\") as q_f:\n",
    "    reader = csv.DictReader(q_f)\n",
    "    for row in reader:\n",
    "        \n",
    "        target_tag = \"python\"\n",
    "        # 判断target_tag在不在里面\n",
    "        tags = row['Tags']\n",
    "        tags = re.sub(r\"[<>]\", \" \", tags).split()\n",
    "        if target_tag not in tags:\n",
    "            continue\n",
    "        \n",
    "        # 判断有没有最佳答案，只要有的\n",
    "        AcceptedAnswerId = row[\"AcceptedAnswerId\"]\n",
    "\n",
    "        if AcceptedAnswerId == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            f_best_answer = AcceptedAnswerId\n",
    "        \n",
    "        # 只有一个答案？都可以\n",
    "        answer_count = eval(row[\"AnswerCount\"])\n",
    "        if answer_count < 2:\n",
    "            pass\n",
    "\n",
    "        q_id = row[\"Id\"]\n",
    "        temp = [q_id]\n",
    "\n",
    "        question_dic[q_id] = now_index\n",
    "        now_index += 1\n",
    "\n",
    "        temp.append(f_best_answer)\n",
    "        temp.append(row[\"AnswerCount\"])\n",
    "        question_infos.append(temp)\n",
    "        \n",
    "        if now_index % 10000 == 0:\n",
    "            print(f\"\\rget {now_index} questions!\", end=\"\")\n",
    "\n",
    "print()\n",
    "question_number = now_index\n",
    "print(\"finally get: \", question_number, \" questions!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d03ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i in range(question_number):\n",
    "    answers.append([])\n",
    "\n",
    "with open(\"./generated_file/a_temp_output.csv\", \"r\") as a_f:\n",
    "    reader = csv.DictReader(a_f)\n",
    "    for row in reader:\n",
    "        q_id = row[\"ParentId\"]\n",
    "        # a_id, score\n",
    "        temp = [row['Id'], row[\"Score\"]]\n",
    "\n",
    "        if question_dic.get(q_id) is None:\n",
    "            continue\n",
    "        answers[question_dic[q_id]].append(temp)\n",
    "\n",
    "\n",
    "# 把信息整合存起来\n",
    "f_out = open(\"generated_file/python_question_info\", \"w\")\n",
    "\n",
    "for i in range(question_number):\n",
    "\n",
    "    # q_id + 1 + answer_count + best_answer_id + answers ...\n",
    "    write_info = question_infos[i][0] + \" 1 \" + question_infos[i][2] + \" \" + question_infos[i][1]\n",
    "    for item in answers[i]:\n",
    "        if item[0] == question_infos[i][1]:\n",
    "            continue\n",
    "        write_info += \" \" + item[0]\n",
    "    write_info += \"\\n\"\n",
    "\n",
    "    f_out.write(write_info)\n",
    "\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e34898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840133\n"
     ]
    }
   ],
   "source": [
    "with open(\"generated_file/python_question_info\", \"r\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab4c4b",
   "metadata": {},
   "source": [
    "# 获得qa的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47cb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ids = []\n",
    "a_ids = []\n",
    "\n",
    "with open(\"generated_file/python_question_info\", \"r\") as f:\n",
    "    for index, line in enumerate(f):\n",
    "        \n",
    "        # q_id + 1 + answer_count + best_answer_id + answers ...\n",
    "        infos = line.split()\n",
    "        answer_num = len(infos) - 3\n",
    "\n",
    "        # 没有最佳答案\n",
    "        if eval(infos[1]) != 1:\n",
    "            continue\n",
    "            \n",
    "        temp_q_id = infos[0]\n",
    "        temp_a_ids = infos[3:]\n",
    "        \n",
    "        q_ids.append(eval(temp_q_id))\n",
    "        \n",
    "        for a in temp_a_ids:\n",
    "            a_ids.append(eval(a))\n",
    "\n",
    "q_ids.sort()\n",
    "a_ids.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_out = open(\"generated_file/python_q_id_content\" + \".csv\", \"w\", newline='')\n",
    "\n",
    "csv_head = [\"id\", \"title\", \"body\"]\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "q_csv_reader = pd.read_csv('generated_file/q_temp_output.csv', index_col=0, chunksize=1000)\n",
    "q_df = next(q_csv_reader)\n",
    "\n",
    "\n",
    "# 开始查表，为了找到body, title, tags\n",
    "for target_id in q_ids:\n",
    "\n",
    "        if q_df.index[0] > target_id:\n",
    "            continue\n",
    "            \n",
    "        while q_df.index[-1] < target_id:\n",
    "            q_df = next(q_csv_reader)\n",
    "        \n",
    "        try:\n",
    "            temp_z = q_df.loc[target_id]\n",
    "            body, title, tags = temp_z[\"Body\"], temp_z[\"Title\"], temp_z[\"Tags\"]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        if title == None or body == None:\n",
    "            continue\n",
    "\n",
    "        out_writer.writerow([target_id, title, body])\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_out = open(\"generated_file/python_a_id_content\" + \".csv\", \"w\", newline='')\n",
    "\n",
    "csv_head = [\"id\", \"body\"]\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "a_csv_reader = pd.read_csv('generated_file/a_temp_output.csv', index_col=0, chunksize=1000)\n",
    "a_df = next(a_csv_reader)\n",
    "\n",
    "\n",
    "# 开始查表，为了找到body, title, tags\n",
    "for target_id in a_ids:\n",
    "\n",
    "        if a_df.index[0] > target_id:\n",
    "            continue\n",
    "            \n",
    "        while a_df.index[-1] < target_id:\n",
    "            a_df = next(a_csv_reader)\n",
    "        \n",
    "        try:\n",
    "            temp_z = a_df.loc[target_id]\n",
    "            body = temp_z[\"Body\"]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        if body is None:\n",
    "            continue\n",
    "\n",
    "        out_writer.writerow([target_id, body])\n",
    "\n",
    "print(\"finished!\")\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a58e93",
   "metadata": {},
   "source": [
    "# 把qa内容处理一下,同时生成corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d035661",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"./glove/qa_corpus\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57aa8200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-59bdbd4d2207c2c3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/yuanhang/.cache/huggingface/datasets/csv/default-59bdbd4d2207c2c3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/yuanhang/.cache/huggingface/datasets/csv/default-59bdbd4d2207c2c3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2ad304dcc74e7d9fdeb0752c76af3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=841.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 先处理问题\n",
    "dataset = load_dataset('csv', data_files='generated_file/python_q_id_content.csv')['train']\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]|@,;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def map_process_data(rows):\n",
    "    global out_file\n",
    "    global REPLACE_BY_SPACE_RE\n",
    "    global GOOD_SYMBOLS_RE\n",
    "\n",
    "    old_body = rows['body']\n",
    "    old_title = rows['title']\n",
    "    \n",
    "    new_body = []\n",
    "    new_title = []\n",
    "    temp_string = \"\"\n",
    "\n",
    "    for index, body in enumerate(old_body):\n",
    "        \n",
    "        # 处理body\n",
    "        text = body\n",
    "        text = re.sub(r\"<pre><code>.*?</code></pre>\", \" HONOCODE \", text, flags=re.DOTALL)\n",
    "        # 然后把尖括号里的东西都删掉\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        text = text.lower()\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text = GOOD_SYMBOLS_RE.sub('', text)\n",
    "        \n",
    "        new_body.append(text)\n",
    "        temp_string += text + \" \"\n",
    "\n",
    "        # 处理title\n",
    "        text = old_title[index]\n",
    "        text = re.sub(r\"<pre><code>.*?</code></pre>\", \" HONOCODE \", text, flags=re.DOTALL)\n",
    "        # 然后把尖括号里的东西都删掉\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        text = text.lower()\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text = GOOD_SYMBOLS_RE.sub('', text)\n",
    "        \n",
    "        new_title.append(text)\n",
    "        temp_string += text + \"\\n\"\n",
    "\n",
    "    out_file.write(temp_string)\n",
    "    return {'title':new_title, 'body':new_body}\n",
    "\n",
    "dataset = dataset.map(function=map_process_data, batched=True, with_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "112cae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存成csv格式\n",
    "content_out = open('generated_file/processed_python_q_id_content.csv', \"w\", newline='')\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "\n",
    "csv_head = [\"id\", \"title\", \"body\"]\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "written_id = dataset['id']\n",
    "written_body = dataset['body']\n",
    "written_title = dataset['title']\n",
    "\n",
    "for index, temp_id in enumerate(written_id):\n",
    "    out_writer.writerow([temp_id, written_title[index], written_body[index]])\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc16275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.close()\n",
    "out_file = open(\"./glove/qa_corpus\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba6eea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-96040d8102891915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/yuanhang/.cache/huggingface/datasets/csv/default-96040d8102891915/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/yuanhang/.cache/huggingface/datasets/csv/default-96040d8102891915/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91d56332c214f98b6ca84e89c01f524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1522.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 处理答案\n",
    "dataset = load_dataset('csv', data_files='generated_file/python_a_id_content.csv')['train']\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]|@,;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def map_process_data(rows):\n",
    "    global out_file\n",
    "    global REPLACE_BY_SPACE_RE\n",
    "    global GOOD_SYMBOLS_RE\n",
    "\n",
    "    old_body = rows['body']\n",
    "    \n",
    "    new_body = []\n",
    "    temp_string = \"\"\n",
    "\n",
    "    for index, body in enumerate(old_body):\n",
    "        # 处理body\n",
    "        text = body\n",
    "        text = re.sub(r\"<pre><code>.*?</code></pre>\", \" HONOCODE \", text, flags=re.DOTALL)\n",
    "        # 然后把尖括号里的东西都删掉\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        text = text.lower()\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text = GOOD_SYMBOLS_RE.sub('', text)\n",
    "        \n",
    "        new_body.append(text)\n",
    "        temp_string += text + \"\\n\"\n",
    "\n",
    "    out_file.write(temp_string)\n",
    "    return {'body':new_body}\n",
    "\n",
    "dataset = dataset.map(function=map_process_data, batched=True, with_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c71e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存成csv格式\n",
    "content_out = open('generated_file/processed_python_a_id_content.csv', \"w\", newline='')\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "\n",
    "csv_head = [\"id\", \"body\"]\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "written_id = dataset['id']\n",
    "written_body = dataset['body']\n",
    "\n",
    "for index, temp_id in enumerate(written_id):\n",
    "    out_writer.writerow([temp_id, written_body[index]])\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6e2bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec902f9",
   "metadata": {},
   "source": [
    "# 把qa内容轻微处理一下，用来做问卷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dece8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-59bdbd4d2207c2c3\n",
      "Reusing dataset csv (/home/yuanhang/.cache/huggingface/datasets/csv/default-59bdbd4d2207c2c3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    }
   ],
   "source": [
    "# 先处理问题\n",
    "dataset = load_dataset('csv', data_files='generated_file/python_q_id_content.csv')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ffa439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'body'],\n",
      "    num_rows: 840133\n",
      "})\n",
      "<p>Does Python have a unit testing framework compatible with the standard xUnit style of test framework? If so, what is it, where is it, and is it any good?</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['body'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c80504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_process_data(rows):\n",
    "    old_body = rows['body']\n",
    "    old_title = rows['title']\n",
    "    \n",
    "    new_body = []\n",
    "    new_title = []\n",
    "    \n",
    "    for index, body in enumerate(old_body):\n",
    "        \n",
    "        # 处理body\n",
    "        text = body\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        new_body.append(text)\n",
    "\n",
    "\n",
    "        # 处理title\n",
    "        text = old_title[index]\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        new_title.append(text)\n",
    "        \n",
    "    return {'title':new_title, 'body':new_body}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb2b65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413f247784bf4da3b763b052bc06c6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=841.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(function=map_process_data, batched=True, with_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4f2a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['body', 'id', 'title'],\n",
      "    num_rows: 840133\n",
      "})\n",
      " Does Python have a unit testing framework compatible with the standard xUnit style of test framework? If so, what is it, where is it, and is it any good? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['body'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存成csv格式\n",
    "content_out = open('generated_file/natural_python_q_id_content.csv', \"w\", newline='')\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "\n",
    "csv_head = [\"id\", \"title\", \"body\"]\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "written_id = dataset['id']\n",
    "written_body = dataset['body']\n",
    "written_title = dataset['title']\n",
    "\n",
    "for index, temp_id in enumerate(written_id):\n",
    "    out_writer.writerow([temp_id, written_title[index], written_body[index]])\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185b73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-96040d8102891915\n",
      "Reusing dataset csv (/home/yuanhang/.cache/huggingface/datasets/csv/default-96040d8102891915/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    }
   ],
   "source": [
    "# 处理答案\n",
    "dataset = load_dataset('csv', data_files='generated_file/python_a_id_content.csv')['train']\n",
    "\n",
    "def map_process_data(rows):\n",
    "    \n",
    "    old_body = rows['body']\n",
    "    new_body = []\n",
    "\n",
    "    for index, body in enumerate(old_body):\n",
    "        # 处理body\n",
    "        text = body\n",
    "        # 然后把尖括号里的东西都删掉\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text, flags=re.DOTALL)\n",
    "        new_body.append(text)\n",
    "\n",
    "    return {'body':new_body}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed424bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee021b126bb47d78dced765383b3880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1522.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(function=map_process_data, batched=True, with_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf10911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存成csv格式\n",
    "content_out = open('generated_file/natural_python_a_id_content.csv', \"w\", newline='')\n",
    "\n",
    "out_writer = csv.writer(content_out)\n",
    "\n",
    "csv_head = [\"id\", \"body\"]\n",
    "out_writer.writerow(csv_head)\n",
    "\n",
    "written_id = dataset['id']\n",
    "written_body = dataset['body']\n",
    "\n",
    "for index, temp_id in enumerate(written_id):\n",
    "    out_writer.writerow([temp_id, written_body[index]])\n",
    "\n",
    "content_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5cb37e",
   "metadata": {},
   "source": [
    "# 计算idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371f9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129519\n"
     ]
    }
   ],
   "source": [
    "# 首先要统计每个词的idf, 不包括<unk>\n",
    "# 建立字典, 包括一些特殊字符\n",
    "my_word2index = {'<pad>': 0, '<unk>': 1, '<sos>': 2, '<eos>': 3, '<cls>': 4}\n",
    "now_index = 5\n",
    "\n",
    "with open(\"/data/yuanhang/important_code/so_python/glove/vocab.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        temp = line.split()\n",
    "        word = temp[0]\n",
    "        if my_word2index.get(word) is None:\n",
    "            my_word2index[word] = now_index\n",
    "            now_index += 1\n",
    "\n",
    "my_index2word = {v:k for k, v in my_word2index.items()}\n",
    "\n",
    "# voc size\n",
    "print(now_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9389c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个词在文档中的出现次数\n",
    "word_appear_count = []\n",
    "document_count = 0\n",
    "\n",
    "for i in range(0, now_index):\n",
    "    word_appear_count.append(0)\n",
    "\n",
    "with open(\"/data/yuanhang/important_code/so_python/glove/qa_corpus\", \"r\") as f:\n",
    "    for line in f:\n",
    "        # 去重复\n",
    "        words = set(line.split())\n",
    "        \n",
    "        if len(words) > 0:\n",
    "            document_count += 1\n",
    "            \n",
    "        for word in words:\n",
    "            index = my_word2index.get(word)\n",
    "            if index is not None:\n",
    "                word_appear_count[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dbef463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129519\n",
      "187397\n"
     ]
    }
   ],
   "source": [
    "print(len(word_appear_count))\n",
    "print(word_appear_count[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c768adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算idf\n",
    "word_idf = []\n",
    "for i in range(0, now_index):\n",
    "    word_idf.append(0)\n",
    "\n",
    "max_idf = -1\n",
    "min_idf = document_count\n",
    "zero_count = 0\n",
    "zero_indices = []\n",
    "\n",
    "for index, value in enumerate(word_appear_count):\n",
    "    if value == 0:\n",
    "        zero_count += 1\n",
    "        zero_indices.append(index)\n",
    "    else:\n",
    "        idf = np.log(document_count/value)\n",
    "        word_idf[index] = idf\n",
    "\n",
    "        if idf < min_idf:\n",
    "            min_idf = idf\n",
    "        if idf > max_idf:\n",
    "            max_idf = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b75b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22294190666590855 14.674845678961981\n",
      "5\n",
      "<pad>\n",
      "<unk>\n",
      "<sos>\n",
      "<eos>\n",
      "<cls>\n"
     ]
    }
   ],
   "source": [
    "print(min_idf, max_idf)\n",
    "\n",
    "print(zero_count)\n",
    "for index in zero_indices:\n",
    "    print(my_index2word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2791569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 my_word2index 和 word_idf 存起来\n",
    "np.save('./generated_file/my_word2index.npy', my_word2index)\n",
    "\n",
    "with open(\"./generated_file/word_idf\", 'w') as f:\n",
    "    for idf in word_idf:\n",
    "        f.write(str(idf)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1bef4",
   "metadata": {},
   "source": [
    "# 整理下question_info,过滤掉有问题的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f83c4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"./generated_file/python_qa_info.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec07f532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['a_ids', 'q_id'],\n",
       "    num_rows: 840128\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce87bf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': 337,\n",
       " 'a_ids': [342,\n",
       "  471,\n",
       "  525,\n",
       "  635,\n",
       "  69410,\n",
       "  69772,\n",
       "  123307,\n",
       "  199213,\n",
       "  202259,\n",
       "  7954780,\n",
       "  13832269,\n",
       "  23143835]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c73fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuanhang/anaconda3/envs/fd/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "q_id_content = pd.read_csv(\"generated_file/processed_python_q_id_content.csv\", index_col=['id'])\n",
    "a_id_content = pd.read_csv(\"generated_file/processed_python_a_id_content.csv\", index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bab33c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body     personally  ive played with several of the bu...\n",
       "Name: 342, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id_content.iloc[0]\n",
    "a_id_content.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28b6125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来存有价值的id\n",
    "my_q_ids = []\n",
    "my_answer_ids = []\n",
    "\n",
    "with open(\"generated_file/python_question_info\") as f:\n",
    "    # q_id + 1 + answer_count + best_answer_id + answers ...\n",
    "    for line in f:\n",
    "        result = line.split()\n",
    "        \n",
    "        temp_q_id = eval(result[0])\n",
    "        temp_a_ids = []\n",
    "        \n",
    "        for temp_a_id in result[3:]:\n",
    "            temp_a_ids.append(eval(temp_a_id))\n",
    "        \n",
    "        # 判断这个问题是不是空的\n",
    "        q_title = q_id_content.loc[temp_q_id]['title']\n",
    "        \n",
    "        try:\n",
    "            best_answer_body = a_id_content.loc[temp_a_ids[0]]['body']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        if q_title is not None and best_answer_body is not None:\n",
    "            my_q_ids.append(temp_q_id)  \n",
    "            my_answer_ids.append(temp_a_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "724ac096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840128\n"
     ]
    }
   ],
   "source": [
    "print(len(my_q_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7234108",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_qa_dict = {'q_id':my_q_ids, 'a_ids':my_answer_ids}\n",
    "my_qa_dict = Dataset.from_dict(my_qa_dict)\n",
    "my_qa_dict.save_to_disk(\"./generated_file/python_qa_info.dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b5300",
   "metadata": {},
   "source": [
    "## 找相关问题，见temp_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "# coding=utf-8\n"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
