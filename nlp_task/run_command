/home/yuanhang/anaconda3/envs/prompt/lib/python3.8/site-packages/transformers/
------------------------------------------------------------------------------------------------------------------------
Task1: mnli/qqp ------------------------------------------------------------
# train bi
python -u nlp_main.py -d qqp --model_class QAClassifierModel --composition pooler -n 1 --label_num 2 --train_batch_size 128 --val_batch_size 128 --no_apex | tee  logs/qqp/bi.log

# train cross
python -u nlp_main.py -d qqp --model_class CrossBERT --composition pooler --label_num 2 --train_batch_size 16 --gradient_accumulation_steps 8  -n 1  | tee  logs/qqp/cross.log

# train ClassifyParallelEncoder
python -u nlp_main.py -d mnli --model_class ClassifyParallelEncoder -n 0 --label_num 3 --train_batch_size 16 --gradient_accumulation_steps 8 --one_stage  --model_save_prefix c10_one_stage_out_vector_base_ --context_num 10 | tee  logs/mnli/c10_one_stage_out_vector.log

# train Deformer
python -u nlp_main.py -d mnli --model_class ClassifyDeformer --top_layer_num 2 --first_seq_max_len 256 -n 1 --label_num 3 --train_batch_size 16 --gradient_accumulation_steps 8 --no_apex --one_stage | tee -a logs/mnli/deformer.log


------------------------------------------------------------------------------------------------------------------------
Task2: ubuntu ------------------------------------------------------------
python -u nlp_main.py -d ubuntu --val_candidate_num 10 --train_candidate_num 2 --model_class ParallelMatchEncoder --composition pooler -n 1 --label_num 0 --train_batch_size 48  --val_batch_size 2 --no_apex --context_num 3 | tee logs/ubuntu/c3_my.log

python -u nlp_main.py -d ubuntu --val_candidate_num 10  --model_class PolyEncoder --composition pooler -n 0 --label_num 0 --train_batch_size 48  --val_batch_size 2  --context_num 16 | tee  -a logs/ubuntu/poly_16.log

python -u nlp_main.py --val_candidate_num 10  -d ubuntu --model_class MatchParallelEncoder --composition pooler -n 1 --label_num 0 --train_batch_size 48 --no_apex  --val_batch_size 4  --context_num 10 --no_initial_test | tee -a logs/ubuntu/c10_my.log

python -u nlp_main.py --label_num 1 --val_candidate_num 10  -d ubuntu --model_class MatchDeformer --no_apex  --val_batch_size 4  -n 0  --train_batch_size 2  --no_initial_test | tee -a logs/ubuntu/deformer.log

python -u nlp_main.py  -d ubuntu --model_class MatchDeformer --label_num 1 --val_candidate_num 10 --top_layer_num 2 --first_seq_max_len 256 -n 0 --train_batch_size 2 --gradient_accumulation_steps 24  --no_apex  --val_batch_size 4  --no_initial_test | tee logs/ubuntu/deformer.log

python -u nlp_main.py -d ubuntu --no_apex --model_class CrossBERT --label_num 1 --train_candidate_num 2 --val_candidate_num 10 --val_batch_size 2 --train_batch_size 16 --gradient_accumulation_steps 8  -n 1 --no_initial_test | tee logs/ubuntu/cross_bs_128.log

************* real test ***********************
1. PolyEncoder
python -u nlp_main.py -d ubuntu --model_class PolyEncoder --val_candidate_num 10 --one_stage --label_num 0 --train_batch_size 128  --val_batch_size 2 -n 1  --no_train --do_real_test --query_block_size 100 --context_num 16
2. Deformer
python -u nlp_main.py -d ubuntu --model_class MatchDeformer --val_candidate_num 10 --one_stage --label_num 1 --train_batch_size 128  --val_batch_size 2 -n 1  --no_train --do_real_test --query_block_size 100 --context_num 16 --top_layer_num 2

------------------------------------------------------------------------------------------------------------------------
Task2: dstc7 ------------------------------------------------------------
# train cross
python -u nlp_main.py -d dstc7 --model_class CrossBERT --composition pooler -n 0 --label_num 1 --train_candidate_num 16 --train_batch_size 2 --gradient_accumulation_steps 64 --val_batch_size 2 --no_initial_test | tee  logs/dstc7/cross_candidate_16.log

# train bi.
python -u nlp_main.py -d dstc7 --model_class QAMatchModel --composition pooler -n 1 --label_num 0 --train_batch_size 48  --val_batch_size 2 --no_apex | tee  -a logs/ubuntu/bi.log

# train mine. gradient_accumulation_steps must be 1!!!!!!!!
python -u nlp_main.py -d dstc7 --model_class MatchParallelEncoder --val_candidate_num 100 --one_stage --label_num 0 --train_batch_size 128  --val_batch_size 2 -n 0 --context_num 3  --model_save_prefix c3_one_stage_out_vector_128_ --no_initial_test | tee -a logs/dstc7/mine_context3_size_128.log

python -u nlp_main.py -d dstc7 --model_class PolyEncoder -n 0 --label_num 0 --train_batch_size 48  --val_batch_size 2 --one_stage --model_save_prefix c16_ --context_num 16 --no_initial_test | tee -a logs/dstc7/poly_encoder_candidate_16.log

# 进行测速
python -u nlp_main.py -d dstc7 --model_class MatchParallelEncoder --val_candidate_num 100 --one_stage --label_num 0 --train_batch_size 128  --val_batch_size 2 -n 1 --context_num 1 --model_save_prefix c3_one_stage_out_vector_128_ --no_train --do_real_test --query_block_size 100

python -u nlp_main.py -d dstc7 --model_class CrossBERT --val_candidate_num 100 --one_stage --label_num 1 --train_candidate_num 16 --train_batch_size 2  --gradient_accumulation_steps 64 --val_batch_size 2 -n 1 --no_train --do_real_test

